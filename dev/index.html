<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · FlashRank.jl</title><meta name="title" content="Home · FlashRank.jl"/><meta property="og:title" content="Home · FlashRank.jl"/><meta property="twitter:title" content="Home · FlashRank.jl"/><meta name="description" content="Documentation for FlashRank.jl."/><meta property="og:description" content="Documentation for FlashRank.jl."/><meta property="twitter:description" content="Documentation for FlashRank.jl."/><meta property="og:url" content="https://svilupp.github.io/FlashRank.jl/"/><meta property="twitter:url" content="https://svilupp.github.io/FlashRank.jl/"/><link rel="canonical" href="https://svilupp.github.io/FlashRank.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>FlashRank.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Features"><span>Features</span></a></li><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Usage"><span>Usage</span></a></li><li><a class="tocitem" href="#Advanced-Usage"><span>Advanced Usage</span></a></li><li><a class="tocitem" href="#Acknowledgments"><span>Acknowledgments</span></a></li></ul></li><li><a class="tocitem" href="api_reference/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/svilupp/FlashRank.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/svilupp/FlashRank.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="FlashRank.jl"><a class="docs-heading-anchor" href="#FlashRank.jl">FlashRank.jl</a><a id="FlashRank.jl-1"></a><a class="docs-heading-anchor-permalink" href="#FlashRank.jl" title="Permalink"></a></h1><p>FlashRank.jl is inspired by the awesome <a href="https://github.com/PrithivirajDamodaran/FlashRank">FlashRank Python package</a>, originally developed by Prithiviraj Damodaran. This package leverages model weights from <a href="https://huggingface.co/prithivida/flashrank">Prithiviraj&#39;s repository on Hugging Face</a> and provides a fast and efficient way to rank documents relevant to any given query without GPUs and large dependencies. This enhances Retrieval Augmented Generation (RAG) pipelines by prioritizing the most suitable documents. The smallest model can be run on almost any machine.</p><h2 id="Features"><a class="docs-heading-anchor" href="#Features">Features</a><a id="Features-1"></a><a class="docs-heading-anchor-permalink" href="#Features" title="Permalink"></a></h2><ul><li>Four ranking models:<ul><li><strong>Tiny (~4MB, INT8):</strong> <a href="https://huggingface.co/cross-encoder/ms-marco-TinyBERT-L-2">ms-marco-TinyBERT-L-2-v2 (default)</a> (alias <code>:tiny</code>)</li><li><strong>MiniLM L-4 (~70MB, FP32):</strong> <a href="https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-4-v2">ms-marco-MiniLM-L-4-v2 ONNX</a> (alias <code>:mini4</code>)</li><li><strong>MiniLM L-6 (~83.4MB, FP32):</strong> <a href="https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-6-v2">ms-marco-MiniLM-L-6-v2 ONNX</a> (alias <code>:mini6</code>)</li><li><strong>MiniLM L-12 (~23MB, INT8):</strong> <a href="https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-12-v2">ms-marco-MiniLM-L-12-v2</a> (alias <code>:mini</code> or <code>mini12</code>)</li></ul></li><li>Lightweight dependencies, avoiding heavy frameworks like Flux and CUDA for ease of integration.</li></ul><p>How fast is it?  With the Tiny model, you can rank 100 documents in ~0.1 seconds on a laptop. With the MiniLM (12 layers) model, you can rank 100 documents in ~0.4 seconds.</p><p>Tip: Pick the largest model that you can afford with your latency budget, ie, MiniLM L-12 is the slowest but has the best accuracy.</p><p>Note that we&#39;re using BERT models with a maximum chunk size of 512 tokens (anything over will be truncated).</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>Add it to your environment simply with:</p><pre><code class="language-julia hljs">using Pkg
Pkg.activate(&quot;.&quot;)
Pkg.add(&quot;FlashRank&quot;)</code></pre><h2 id="Usage"><a class="docs-heading-anchor" href="#Usage">Usage</a><a id="Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Usage" title="Permalink"></a></h2><p>Ranking your documents for a given query is as simple as:</p><pre><code class="language-julia hljs">using FlashRank

ranker = RankerModel() # Defaults to model = `:tiny`

query = &quot;How to speedup LLMs?&quot;
passages = [
        &quot;Introduce *lookahead decoding*: - a parallel decoding algo to accelerate LLM inference - w/o the need for a draft model or a data store - linearly decreases # decoding steps relative to log(FLOPs) used per decoding step.&quot;,
        &quot;LLM inference efficiency will be one of the most crucial topics for both industry and academia, simply because the more efficient you are, the more \$\$\$ you will save. vllm project is a must-read for this direction, and now they have just released the paper&quot;,
        &quot;There are many ways to increase LLM inference throughput (tokens/second) and decrease memory footprint, sometimes at the same time. Here are a few methods I’ve found effective when working with Llama 2. These methods are all well-integrated with Hugging Face. This list is far from exhaustive; some of these techniques can be used in combination with each other and there are plenty of others to try. - Bettertransformer (Optimum Library): Simply call `model.to_bettertransformer()` on your Hugging Face model for a modest improvement in tokens per second. - Fp4 Mixed-Precision (Bitsandbytes): Requires minimal configuration and dramatically reduces the model&#39;s memory footprint. - AutoGPTQ: Time-consuming but leads to a much smaller model and faster inference. The quantization is a one-time cost that pays off in the long run.&quot;,
        &quot;Ever want to make your LLM inference go brrrrr but got stuck at implementing speculative decoding and finding the suitable draft model? No more pain! Thrilled to unveil Medusa, a simple framework that removes the annoying draft model while getting 2x speedup.&quot;,
        &quot;vLLM is a fast and easy-to-use library for LLM inference and serving. vLLM is fast with: State-of-the-art serving throughput Efficient management of attention key and value memory with PagedAttention Continuous batching of incoming requests Optimized CUDA kernels&quot;,
];


result = rank(ranker, query, passages)</code></pre><p><code>result</code> is of type <code>RankResult</code> and contains the sorted passages, their scores (0-1, where 1 is the best) and the positions of the sorted documents (referring to the original <code>passages</code> vector).</p><p>Here&#39;s a brief outline of how you can integrate FlashRank.jl into your <a href="https://github.com/svilupp/PromptingTools.jl">PromptingTools.jl</a> RAG pipeline.</p><p>For a full example, see <code>examples/prompting_tools_integration.jl</code>.</p><pre><code class="language-julia hljs">using FlashRank
using PromptingTools
using PromptingTools.Experimental.RAGTools
const RT = PromptingTools.Experimental.RAGTools

# Wrap the model to be a valid Ranker recognized by RAGTools
# It will be provided to the airag/rerank function to avoid instantiating it on every call
struct FlashRanker &lt;: RT.AbstractReranker
    model::RankerModel
end
reranker = RankerModel(:tiny) |&gt; FlashRanker

# Define the method for ranking with it
function RT.rerank(
        reranker::FlashRanker, index::RT.AbstractDocumentIndex, question::AbstractString,
        candidates::RT.AbstractCandidateChunks; kwargs...)
    ## omitted for brevity
    ## See examples/prompting_tools_integration.jl for details
end

## Apply to the pipeline configuration, eg, 
cfg = RAGConfig(; retriever=RT.AdvancedRetriever(; reranker))
## assumes existing index
question = &quot;Tell me about prehistoric animals&quot;
result = airag(cfg, index; question, return_all = true)</code></pre><h2 id="Advanced-Usage"><a class="docs-heading-anchor" href="#Advanced-Usage">Advanced Usage</a><a id="Advanced-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Usage" title="Permalink"></a></h2><p>You can also leverage quite &quot;coarse&quot; but fast embeddings with the <code>tiny_embed</code> model (Bert-L4).</p><pre><code class="language-julia hljs">embedder = FlashRank.EmbedderModel(:tiny_embed)

passages = [&quot;This is a test&quot;, &quot;This is another test&quot;]
result = FlashRank.embed(embedder, passages)</code></pre><h2 id="Acknowledgments"><a class="docs-heading-anchor" href="#Acknowledgments">Acknowledgments</a><a id="Acknowledgments-1"></a><a class="docs-heading-anchor-permalink" href="#Acknowledgments" title="Permalink"></a></h2><ul><li><a href="https://github.com/PrithivirajDamodaran/FlashRank">FlashRank</a> and <a href="https://github.com/chengchingwen/Transformers.jl">Transformers.jl</a> have been essential in the development of this package.</li><li>Special thanks to Prithiviraj Damodaran for the original FlashRank and model weights.</li><li>And to Transformers.jl for the WordPiece implementation and BERT tokenizer which have been forked for this package (to minimize dependencies).</li></ul></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="api_reference/">API Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Sunday 7 July 2024 09:32">Sunday 7 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
